import json
import sqlite3
import os
from pathlib import Path

# 데이터베이스 파일 경로 입력 받기
db_path = input("데이터베이스 파일 경로를 입력하세요: ")

# 데이터베이스 파일이 존재하는지 확인
if not os.path.exists(db_path):
    print("입력한 경로에 데이터베이스 파일이 존재하지 않습니다.")
    exit()

output_dir = "malware_analysis_results"  # 결과 저장할 디렉토리

# 결과 저장 디렉토리 생성
os.makedirs(output_dir, exist_ok=True)

# 데이터베이스 연결
conn = sqlite3.connect(db_path)
cursor = conn.cursor()

# 검색할 테이블 목록 (파일 이름 초기 추출용)
tables_to_search = {
    "Edge_Chromium_Downloads": "Download_Source",
    "Chrome_Downloads": "Download_Source"
}

keys = list(tables_to_search.keys())    
print(f"Processing {os.path.basename(db_path)}: {keys}")

# 추가로 검색할 테이블과 해당 컬럼
another_table_to_search = {
    "AutoRun_Items": ["File_Name"],
    "LogFile_Analysis": ["Current_File_Name", "Original_File_Name"],
    "LNK_Files": ["Linked_Path"],
    "MRU_Recent_Files_and_Folders": ["File_Folder_Name"],  # & 기호 제거
    "MRU_Opened_Saved_Files": ["File_Name"],  # / 기호 제거
    "Prefetch_Files_Windows_8_10": ["Application_Name"],  # 특수문자 제거
    "SRUM_Application_Resource_Usage": ["Application_Name"],
    "SRUM_Network_Usage": ["Application_Name"],
    "Shim_Cache": ["File_Name"],
    "Startup_Items": ["Path"],
    "Windows_Event_Logs": ["Event_Data"],
    "AmCache_File_Entries": ["Name"],
    "UserAssist": ["File_Name"],
    "Scheduled_Tasks": ["Actions"],
    "UsnJrnl": ["File_Name"]
}

# 데이터베이스의 모든 테이블 이름 가져오기
cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
existing_tables = {row[0] for row in cursor.fetchall()}

# 테이블 이름 매핑 생성
table_mapping = {
    "MRU_Recent_Files_&_Folders": "MRU_Recent_Files_and_Folders",
    "MRU_Opened/Saved_Files": "MRU_Opened_Saved_Files",
    '"Prefetch_Files___Windows_8/10"': "Prefetch_Files_Windows_8_10"
}

# 각 테이블의 시간 컬럼 이름을 저장할 딕셔너리
time_column_mapping = {
    "AutoRun_Items": "Registry_Key_Modified_Date/Time_-_UTC_(yyyy-mm-dd)",
    "LogFile_Analysis": "Event_Date/Time_-_UTC_(yyyy-mm-dd)",
    "LNK_Files": "Created_Date/Time_-_UTC_(yyyy-mm-dd)",
    "MRU_Recent_Files_and_Folders": "Registry_Key_Modified_Date/Time_-_UTC_(yyyy-mm-dd)",  # & 기호 제거
    "MRU_Opened_Saved_Files": "Registry_Key_Modified_Date/Time_-_UTC_(yyyy-mm-dd)",  # / 기호 제거
    "Prefetch_Files_Windows_8_10": ["4th_Last_Run_Date/Time_-_UTC_(yyyy-mm-dd)", "File_Created_Date/Time_-_UTC_(yyyy-mm-dd)", "7th_Last_Run_Date/Time_-_UTC_(yyyy-mm-dd)", "2nd_Last_Run_Date/Time_-_UTC_(yyyy-mm-dd)", "3rd_Last_Run_Date/Time_-_UTC_(yyyy-mm-dd)", "5th_Last_Run_Date/Time_-_UTC_(yyyy-mm-dd)", "6th_Last_Run_Date/Time_-_UTC_(yyyy-mm-dd)", "8th_Last_Run_Date/Time_-_UTC_(yyyy-mm-dd)", "Last_Run_Date/Time_-_UTC_(yyyy-mm-dd)"],  # 특수문자 제거
    "SRUM_Application_Resource_Usage": "Recorded_Timestamp_Date/Time_-_UTC_(yyyy-mm-dd)",
    "SRUM_Network_Usage": "Recorded_Timestamp_Date/Time_-_UTC_(yyyy-mm-dd)",
    "Shim_Cache": "Key_Last_Updated_Date/Time_-_UTC_(yyyy-mm-dd)",
    "Startup_Items": "Last_Modified_Date/Time_-_UTC_(yyyy-mm-dd)",
    "Windows_Event_Logs": "Created_Date/Time_-_UTC_(yyyy-mm-dd)",
    "AmCache_File_Entries": "Key_Last_Updated_Date/Time_-_UTC_(yyyy-mm-dd)",
    "UserAssist": "Last_Run_Date/Time_-_UTC_(yyyy-mm-dd)",
    "Scheduled_Tasks": "Created_Date/Time_-_Local_Time_(yyyy-mm-dd)",
    "UsnJrnl": "Timestamp_Date/Time_-_UTC_(yyyy-mm-dd)"
}

# Prefetch_Files_Windows_8_10의 시간 컬럼 처리
prefetch_time_columns = time_column_mapping.get("Prefetch_Files_Windows_8_10", [])

# 파일 이름 리스트 가져오기
target_files = set()
for table in keys:
    if table not in existing_tables:
        print(f"Skipping table {table}: does not exist.")
        continue
    try:
        cursor.execute(f"SELECT File_Name FROM {table};")
        rows = cursor.fetchall()
        for row in rows:
            if row[0]:  # 파일 이름이 존재하면 추가
                target_files.add(row[0])
    except sqlite3.Error as e:
        print(f"Error accessing table {table}: {e}")

# 타겟 파일 이름별 결과 저장용 딕셔너리
grouped_results = {file_name: {} for file_name in target_files}

# 각 타겟 파일에 대해 다른 테이블에서 관련 데이터 검색
for target_file in target_files:
    for table, columns in another_table_to_search.items():
        # 실제 테이블 이름 찾기
        actual_table = table
        for old_name, new_name in table_mapping.items():
            if new_name == table:
                actual_table = old_name
                break

        if actual_table.strip('"') not in existing_tables:
            print(f"Skipping table {actual_table}: does not exist.")
            continue
        
        grouped_results[target_file][table] = []  # 결과 초기화
        try:
            # 각 테이블의 지정된 컬럼에서 데이터 가져오기
            for column in columns:
                query = f"""
                SELECT *
                FROM {actual_table}
                WHERE {column} LIKE '%{target_file}%';
                """
                cursor.execute(query)
                rows = cursor.fetchall()

                # 테이블의 컬럼 이름 가져오기
                cursor.execute(f"PRAGMA table_info({actual_table});")
                column_names = [col[1] for col in cursor.fetchall()]

                # 타겟 파일 이름과 매칭되는 ROW 저장
                for row in rows:
                    grouped_results[target_file][table].append(
                        dict(zip(column_names, row))
                    )

            # Prefetch_Files_Windows_8_10 테이블의 시간 컬럼 처리
            if table == "Prefetch_Files_Windows_8_10":
                for time_column in prefetch_time_columns:
                    try:
                        query = f"""
                        SELECT {time_column}
                        FROM {actual_table}
                        WHERE Application_Name LIKE '%{target_file}%';
                        """
                        cursor.execute(query)
                        rows = cursor.fetchall()

                        # 시간값을 저장할 리스트
                        time_values = [row[0] for row in rows if row[0]]

                        # 가장 최근의 시간값 선택
                        if time_values:
                            latest_time = max(time_values)
                            grouped_results[target_file][table].append({
                                "Latest_Time": latest_time
                            })
                    except sqlite3.Error as e:
                        print(f"Error accessing table {actual_table}: {e}")

        except sqlite3.Error as e:
            print(f"Error accessing table {actual_table}: {e}")

    # .zip 파일인 경우 file_content_datas 테이블 검색
    if target_file.lower().endswith('.zip') and 'file_content_datas' in existing_tables:
        try:
            query = """
            SELECT *
            FROM file_content_datas
            WHERE content LIKE ?;
            """
            cursor.execute(query, (f'%{target_file}%',))
            rows = cursor.fetchall()

            cursor.execute("PRAGMA table_info(file_content_datas);")
            column_names = [col[1] for col in cursor.fetchall()]

            grouped_results[target_file]['file_content_datas'] = [
                dict(zip(column_names, row)) for row in rows
            ]

            for row_dict in grouped_results[target_file]['file_content_datas']:
                hit_id = row_dict.get('hit_id')
                if hit_id:
                    # Prefetch 테이블에서 Application_Name 가져오기
                    prefetch_query = """
                    SELECT Application_Name
                    FROM "Prefetch_Files___Windows_8/10"
                    WHERE hit_id = ?;
                    """
                    cursor.execute(prefetch_query, (hit_id,))
                    app_names = [row[0] for row in cursor.fetchall() if row[0]]

                    for app_name in app_names:
                        # LNK_Files에서 Accessed_Date/Time 가져오기
                        lnk_query = """
                        SELECT "Accessed_Date/Time_-_UTC_(yyyy-mm-dd)"
                        FROM LNK_Files 
                        WHERE Linked_Path LIKE ?
                        ORDER BY "Accessed_Date/Time_-_UTC_(yyyy-mm-dd)";
                        """
                        cursor.execute(lnk_query, (f'%{app_name}%',))
                        access_times = [row[0] for row in cursor.fetchall() if row[0]]

                        for access_time in access_times:
                            # LogFile_Analysis에서 Create 이벤트 찾기
                            log_query = """
                            SELECT *
                            FROM LogFile_Analysis
                            WHERE "Event_Date/Time_-_UTC_(yyyy-mm-dd)" > ?
                            AND File_Operation = 'Create'
                            AND (Current_File_Name LIKE '%.exe' OR Original_File_Name LIKE '%.exe')
                            ORDER BY "Event_Date/Time_-_UTC_(yyyy-mm-dd)"
                            LIMIT 5;
                            """
                            cursor.execute(log_query, (access_time,))
                            log_rows = cursor.fetchall()

                            cursor.execute("PRAGMA table_info(LogFile_Analysis);")
                            log_columns = [col[1] for col in cursor.fetchall()]

                            # 각 로그 행을 딕셔너리로 변환하고 시간 비교
                            filtered_rows = []
                            for row in log_rows:
                                row_dict = dict(zip(log_columns, row))
                                created_time = row_dict.get('Current_Created_Date/Time_-_UTC_(yyyy-mm-dd)')
                                accessed_time = row_dict.get('Current_Accessed_Date/Time_-_UTC_(yyyy-mm-dd)')
                                modified_time = row_dict.get('Current_Modified_Date/Time_-_UTC_(yyyy-mm-dd)')

                                # 모든 시간값이 존재하는 경우에만 비교
                                if all([created_time, accessed_time, modified_time]):
                                    # modified_time이 created_time과 accessed_time보다 과거인 경우만 포함
                                    if modified_time < created_time and modified_time < accessed_time:
                                        filtered_rows.append(row_dict)

                            grouped_results[target_file]['Related_Create_Events'] = filtered_rows

        except sqlite3.Error as e:
            print(f"Error accessing tables: {e}")

# 각 다운로드 파일별로 Web Visits 데이터 가져오기
for target_file in target_files:
    web_visits_results = []
    
    # 다운로드 시간 가져오기
    for table in keys:
        if table not in existing_tables:
            continue
            
        try:
            query = f'''
            SELECT "Start_Time_Date/Time_-_UTC_(yyyy-mm-dd)"
            FROM "{table}"
            WHERE File_Name = ?;
            '''
            cursor.execute(query, (target_file,))
            row = cursor.fetchone()
            
            if row and row[0]:  # 시간값이 존재하면
                start_time = row[0]
                
                # 해당 브라우저의 Web Visits 테이블 선택
                if table == "Edge_Chromium_Downloads" and "Edge_Chromium_Web_Visits" in existing_tables:
                    web_visit_table = "Edge_Chromium_Web_Visits"
                elif table == "Chrome_Downloads" and "Chrome_Web_Visits" in existing_tables:
                    web_visit_table = "Chrome_Web_Visits"
                else:
                    continue

                # Web Visits 데이터 가져오기
                try:
                    query = f'''
                    SELECT *
                    FROM "{web_visit_table}"
                    WHERE "Date_Visited_Date/Time_-_UTC_(yyyy-mm-dd)" < ?
                    ORDER BY "Date_Visited_Date/Time_-_UTC_(yyyy-mm-dd)" DESC
                    LIMIT 2;
                    '''
                    cursor.execute(query, (start_time,))
                    rows = cursor.fetchall()

                    cursor.execute(f'PRAGMA table_info("{web_visit_table}");')
                    column_names = [col[1] for col in cursor.fetchall()]

                    for row in rows:
                        web_visits_results.append(dict(zip(column_names, row)))
                        
                except sqlite3.Error as e:
                    print(f"Error accessing table {web_visit_table}: {e}")
                    
        except sqlite3.Error as e:
            print(f"Error accessing table {table}: {e}")
            
    # 결과 저장
    grouped_results[target_file]['Web_Visits'] = web_visits_results

# JSON으로 결과 저장
db_name = os.path.splitext(os.path.basename(db_path))[0]
output_file = os.path.join(output_dir, f"{db_name}_results.json")

# 최종 결과를 저장할 리스트
final_results = []

for target_file, data in grouped_results.items():
    web_visits = data.get('Web_Visits', [])
    print(f"Debug: Processing target_file: {target_file}, Web Visits: {web_visits}")

    # 압축 해제 여부 초기화
    unzipped = False

    # 압축 해제 파일을 포함하여 모든 파일을 최종 결과에 저장
    if any(visit and '_Mail_' in (visit.get('_TAG_', '') or '') for visit in web_visits) or unzipped:
        # Timestamp
        timestamp = min(visit["Date_Visited_Date/Time_-_UTC_(yyyy-mm-dd)"] for visit in web_visits if visit)
        print(f"Debug: Timestamp: {timestamp}")

        # Filename
        filename = target_file
        print(f"Debug: Filename: {filename}")

        # Browser
        browser = web_visits[0].get('artifact_name', '').split(' ')[0] if web_visits else 'Unknown'
        print(f"Debug: Browser: {browser}")

        # Description_Connection
        description_connection = []
        for table, entries in data.items():
            if table in another_table_to_search:
                for entry in entries:
                    hit_id = entry.get('hit_id', 'N/A')
                    print(f"Debug: Table: {table}, Hit ID: {hit_id}")

                    # 시간값 추출
                    time_column = time_column_mapping.get(table, 'N/A')
                    time_value = entry.get(time_column, 'N/A')
                    print(f"Debug: Time Column: {time_column}, Time Value: {time_value}")

                    description_connection.append(f"{table}: {hit_id}, {time_value}")

                    # 압축 해제 여부 확인
                    if entry.get('Unzipped', False):
                        unzipped = True

        # Timeline
        time_values = [entry.split(', ')[-1] for entry in description_connection if ', ' in entry]
        latest_time = max(time_values) if time_values else 'N/A'
        print(f"Debug: Latest Time: {latest_time}")

        timeline = f"{timestamp} ~ {latest_time}"
        print(f"Debug: Timeline: {timeline}")

        # 결과 추가
        final_results.append({
            "Timestamp": timestamp,
            "Filename": filename,
            "Browser": browser,
            "Description_Connection": description_connection,
            "Timeline": timeline,
            "Unzipped": unzipped  # 압축 해제 여부 추가
        })

# JSON 파일로 저장
with open(output_file, "w", encoding="utf-8") as json_file:
    json.dump(grouped_results, json_file, indent=4, ensure_ascii=False)

# final_results를 별도의 JSON 파일로 저장
final_results_file = os.path.join(output_dir, f"{db_name}_final_results.json")
with open(final_results_file, "w", encoding="utf-8") as json_file:
    json.dump(final_results, json_file, indent=4, ensure_ascii=False)

print(f"Final results for {db_name} have been saved to {final_results_file}")

# 데이터베이스 연결 종료
conn.close()
